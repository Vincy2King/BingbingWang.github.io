<!DOCTYPE html>
<html>
<head>
    <title>VLM</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="author" content="">
    <meta name="keywords" content="">
    <meta name="description" content="">
    <link href="https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/5.3.0-alpha3/css/bootstrap.min.css"
          rel="stylesheet">
    <link id="theme" rel="stylesheet" type="text/css" href="../css/greyson-theme.css">
    <link rel="stylesheet" type="text/css" href="../style.css">
    <link rel="stylesheet" type="text/css" href="../fonts/icomoon/icomoon.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Mulish:ital@0;1&family=Oswald:wght@500&display=swap"
          rel="stylesheet">

    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>VLM</title>
    <meta name="keywords" content="Corporate Business Shopse HTML5 Css3 Template App Product">
    <meta name="description" content="appnox - Product Landing HTML5 Template">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="../image/x-icon" href="../assets/img/favicon.ico">

    <!-- css here -->
    <link rel="stylesheet" href="../static/css/bootstrap.min.css">
    <link rel="stylesheet" href="../static/css/meanmenu.css">
    <link rel="stylesheet" href="../static/css/animate.min.css">
    <link rel="stylesheet" href="../static/css/magnific-popup.css">
    <link rel="stylesheet" href="../static/css/fontawesome-all.min.css">
    <link rel="stylesheet" href="../static/css/owl.carousel.min.css">
    <link rel="stylesheet" href="../static/css/owl.theme.default.min.css">
    <link rel="stylesheet" href="../static/css/scrolltop.css">
    <link rel="stylesheet" href="../static/css/default.css">
    <link rel="stylesheet" href="../static/css/style.css">
    <link rel="stylesheet" href="../static/css/responsive.css">
</head>
<body>

<div class="pattern-bg"></div>

<header id="header">
    <nav class="navbar navbar-expand-lg navbar-light">
        <div class="container-fluid">
            <a class="navbar-brand" href="../index.html"><img src="../images/logo.png" alt="logo"></a>
            <button class="navbar-toggler" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvasNavbar"
                    aria-controls="offcanvasNavbar">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="offcanvas offcanvas-end" tabindex="-1" id="offcanvasNavbar"
                 aria-labelledby="offcanvasNavbarLabel">
                <div class="offcanvas-header">
                    <h5 class="offcanvas-title" id="offcanvasNavbarLabel">Offcanvas</h5>
                    <button type="button" class="btn-close text-reset" data-bs-dismiss="offcanvas"
                            aria-label="Close"></button>
                </div>
                <div class="offcanvas-body">
                    <ul class="navbar-nav justify-content-end fw-bold fs-6 text-uppercase flex-grow-1 pe-3 gap-3">
                        <li class="nav-item">
                            <a class="nav-link active" aria-current="page" href="index.html">Home</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#"></a>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#" id="dropdownId" data-bs-toggle="dropdown"
                               aria-haspopup="true" aria-expanded="false">Pages</a>
                            <div class="dropdown-menu" aria-labelledby="dropdownId">
                                <a class="dropdown-item" href="../index.html">Blog</a>
                                <a class="dropdown-item" href="../index.html">Blog Single</a>
                            </div>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#">Blog</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#">Contact</a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </nav>
</header>

<main>
    <div id="appnox-latest-blog-area">
        <div class="container">
            <div class="row">
                <div class="blog-details-wraper">
                    <div class="blog-details-content">

                        <h2 style="font-weight: bold;text-align: center;color: black"> Investigation of TPAMI Paper </h2>
                        <p style="font-size: 20px;color: darkgrey;text-align: center">创建日期：2024年06月04日</p>


                        <h3 id="section1" style="color: coral;margin-top: 50px;font-weight: bold">Summarizaiton
                        </h3>
                        <p>总体上看，TPAMI 很少有针对NLP情感的工作，从情感 情绪等关键词进行所有后得到的工作，虽然有图像情绪预测、语音情绪预测、眼动信号、脑电情绪预测、微表情情绪预测，以及人脸情绪预测，但是这些的工作也是很少。
                            另外，没有sarcasm和stance的相关工作。这个期刊本身就是偏向模式识别，多模态的工作有很多，但是多模态情感/情绪的工作确实也没有。
                            之前我有个Gaze-based image caption的工作就有审稿人建议投TPAMI。</p>
                        <p>研究一下它最新发表的paper，以及popular paper，除了一些看不懂的（比如Light Scanners）外，一般有三种偏向：</p>
                        <p> &emsp;&emsp;&emsp;（1）综述：包括multimodal transformer, eye-tracking, object detection等；</p>
                        <p> &emsp;&emsp;&emsp;（2）机器学习，比如implicit regularization of dropout；</p>
                        <p> &emsp;&emsp;&emsp;（3）多模态（或者说更侧重于image），包括diffusion,image caption, object detection以及一些视频相关的内容，像ERC或许就可以。 </p>

                        <h3 id="section2" style="color: coral;margin-top: 50px;font-weight: bold">Related Paper
                        </h3>
                        <h5>1. 2022 Affective Image Content Analysis: Two Decades Review and New Perspectives（图像情绪综述，目前我的工作其中就参考了一部分这篇文章）</h5>
                        <p>图像可以传达丰富的语义，并在观众中引发各种情绪。近年来，随着情绪智能的快速发展和视觉数据的爆炸式增长，人们对情感图像内容分析进行了广泛的研究。
                            在这项调查中，作者全面回顾近二十年来AICA的发展，特别是针对三个主要挑战——情感差距、感知主观性以及标签噪音和缺失——关注最先进的方法。</p>
                        <h5>2. 2023 Brain-Machine Coupled Learning Method for Facial Emotion Recognition（基于脑电的人脸情绪识别）</h5>
                        <p>机器学习的神经网络模型在视觉任务中显示出了很好的前景，例如面部情绪识别。然而，从具有少量样本的数据集训练的模型的泛化是有限的。
                            与机器不同，人脑可以有效地从少数样本中实现所需的信息，以完成视觉任务。为了学习大脑的泛化能力，该工作提出了一种新的用于面部情绪识别的脑机耦合学习方法，
                            让神经网络同时学习机器的视觉知识和大脑的认知知识。所提出的方法利用视觉图像和脑电信号在视觉和认知领域对模型进行耦合训练。
                            每个领域模型由两种类型的交互渠道组成，公共渠道和私有渠道。由于脑电信号可以反映大脑活动，因此大脑的认知过程是通过逆向工程的模型来解码的。
                            对面部情绪图像诱导的脑电信号进行解码，视觉域的公共通道可以接近认知域的认知过程。此外，使用对抗性策略在每个私有通道中找到每个领域特有的知识。学习后，在没有脑电信号参与的情况下，仅使用视觉域中两个通道的级联来基于机器的视觉知识和从大脑学习的认知知识对面部情绪图像进行分类。</p>

                        <h5>3. Context Based Emotion Recognition Using EMOTIC Dataset（图像情绪预测）</h5>
                        <p>在我们的日常生活和社交活动中，我们经常试图感知人们的情绪状态。已经有很多研究为机器提供类似的识别情绪的能力。
                            从计算机视觉的角度来看，以前的大部分工作都集中在分析面部表情，在某些情况下，还包括身体姿势。其中一些方法在特定环境中效果非常好。
                            然而，在自然、无约束的环境中，它们的性能是有限的。心理学研究表明，除了面部表情和身体姿势外，场景背景还为我们感知人们的情绪提供了重要信息。
                            然而，用于自动情绪识别的上下文处理尚未得到深入探索，部分原因是缺乏适当的数据。
                            该工作介绍了EMOTIC，这是一个由处于不同自然环境中的人的图像数据集，用他们明显的情绪进行注释。情绪数据集结合了两种不同类型的情绪表示：
                            （1）一组26个离散类别，以及（2）连续维度Valence、Arousal和显性。作者还对数据集进行了详细的统计和算法分析，以及注释者的一致性分析。
                            使用情绪数据集，训练不同的CNN模型进行情绪识别，将包含人物的边界框的信息与从场景中提取的上下文信息相结合。</p>

                        <h5>4. 2023 Dawn of the Transformer Era in Speech Emotion Recognition: Closing the Valence Gap</h5>
                        <p>基于Transformer的架构的最新进展在一些机器学习任务中显示出了前景。在音频领域，这种架构已经成功地应用于语音情感识别领域。
                            然而，现有的工作没有评估模型大小和预训练数据对下游性能的影响，并且对泛化、鲁棒性、公平性和效率的关注有限。
                            本论文对wav2vec 2.0和HuBERT的几个预训练变体进行了全面的分析，我们对MSP播客的唤醒、优势和效价维度进行了微调，
                            同时还使用IEMOCAP和MOSI来测试跨语料库泛化。</p>

                        <h5>5. 2024 COLD Fusion: Calibrated and Ordinal Latent Distribution Fusion for Uncertainty-Aware Multimodal Emotion Recognition</h5>
                        <p>从人脸和语音中自动识别明显的情绪很困难，部分原因是各种不确定性来源，包括输入数据和机器学习框架中使用的标签。
                            本文介绍了一种不确定性感知的多模式融合方法，该方法量化情绪预测中的模态或数据不确定性。
                            具体而言，本文提出了一种新的融合框架，其中通过约束其方差来学习单峰时间上下文上的潜在分布。
                            这些方差约束，校准和顺序排序，被设计为使得为一种模态估计的方差可以表示该模态的时间上下文在情感识别方面的信息量。
                            当校准良好时，模态不确定性分数表明其相应的预测可能与基本事实标签有多大差异。排名良好的不确定性分数允许在不同模态上对不同帧进行有序排名。
                            为了共同施加这两个约束，本文提出了一个softmax分布匹配损失。</p>

                        <h5>6. 2021 SEWA DB: A Rich Database for Audio-Visual Emotion and Sentiment Research in the Wild</h5>
                        <p>随着数字设备越来越成为我们生活中不可或缺的一部分，人们比以往任何时候都更需要在野外实现强大性能的自然人机交互和视听人类行为传感系统。
                            准确注释的真实世界数据是设计此类系统的关键。然而，现有的数据库通常考虑受控的环境、低的人口变异性和单一的任务。
                            本文介绍了SEWA数据库，该数据库包含来自六种文化的398人的2000多分钟视听数据，其中50%为女性，年龄范围从18岁到65岁。
                            受试者被记录在两种不同的环境中：观看广告和在视频聊天中讨论广告。该数据库包括面部标志、面部动作单位（FAU）、各种发声、
                            镜像以及持续值的效价、唤醒、喜好、一致性和（不）喜好的原型示例等方面的丰富记录注释。
                            该数据库旨在为情感计算和人类自动感知领域的研究人员提供极其宝贵的资源，并有望推动包括文化研究在内的人类行为分析研究。</p>

                        <h5>7. 2008 Emotion recognition based on physiological changes in music listening</h5>
                        <p>到目前为止，与诸如面部表情或语音的视听情绪通道相比，用于情绪识别的生理信号很少受到关注。
                            本文研究了生理信号作为情绪识别可靠渠道的潜力。讨论了自动识别系统的所有基本阶段，从生理数据集的记录到基于特征的多类别分类。
                            为了在数周内收集多个受试者的生理数据集，我们使用了一种音乐诱导方法，在没有任何刻意的实验室设置的情况下，自发地引导受试者进入真实的情绪状态。
                            四通道生物传感器用于测量肌电图、心电图、皮肤电导率和呼吸变化。
                            提出了来自不同分析领域的广泛生理特征，包括时间/频率、熵、几何分析、子带谱、多尺度熵等，以找到最佳的情绪相关特征，并将其与情绪状态相关联。
                            对提取的最佳特征进行了详细说明，并通过分类结果验证了其有效性。
                            通过使用扩展线性判别分析（pLDA）对四种音乐情绪（正/高唤醒、负/高唤醒，负/低唤醒和正/低唤醒）进行分类。
                            此外，通过利用2D情绪模型的二分法性质，本文开发了一种新的情绪特异性多级二分法分类（EMDC）方案，并将其性能与使用pLDA的直接多类分类进行了比较。</p>

                    </div>
                </div>
            </div>
        </div>
    </div>
</main>
<script src="../js/jquery-1.11.0.min.js"></script>
<script src="https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/5.3.0-alpha3/js/bootstrap.bundle.min.js"
        integrity="sha384-ENjdO4Dr2bkBIFxQpeoTz1HIcje39Wm4jDKdf19U8gI4ddQ3GYNS7NTKfAdVQSZe"
        crossorigin="anonymous"></script>
</body>
</html>
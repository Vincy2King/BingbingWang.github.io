<!DOCTYPE html>
<html>
<head>
    <title>VLM</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="author" content="">
    <meta name="keywords" content="">
    <meta name="description" content="">
    <link href="https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/5.3.0-alpha3/css/bootstrap.min.css"
          rel="stylesheet">
    <link id="theme" rel="stylesheet" type="text/css" href="../css/greyson-theme.css">
    <link rel="stylesheet" type="text/css" href="../style.css">
    <link rel="stylesheet" type="text/css" href="../fonts/icomoon/icomoon.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Mulish:ital@0;1&family=Oswald:wght@500&display=swap"
          rel="stylesheet">

    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>VLM</title>
    <meta name="keywords" content="Corporate Business Shopse HTML5 Css3 Template App Product">
    <meta name="description" content="appnox - Product Landing HTML5 Template">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" type="image/x-icon" href="../assets/img/favicon.ico">

    <!-- css here -->
    <link rel="stylesheet" href="../static/css/bootstrap.min.css">
    <link rel="stylesheet" href="../static/css/meanmenu.css">
    <link rel="stylesheet" href="../static/css/animate.min.css">
    <link rel="stylesheet" href="../static/css/magnific-popup.css">
    <link rel="stylesheet" href="../static/css/fontawesome-all.min.css">
    <link rel="stylesheet" href="../static/css/owl.carousel.min.css">
    <link rel="stylesheet" href="../static/css/owl.theme.default.min.css">
    <link rel="stylesheet" href="../static/css/scrolltop.css">
    <link rel="stylesheet" href="../static/css/default.css">
    <link rel="stylesheet" href="../static/css/style.css">
    <link rel="stylesheet" href="../static/css/responsive.css">
</head>
<body>

<div class="pattern-bg"></div>

<header id="header">
    <nav class="navbar navbar-expand-lg navbar-light">
        <div class="container-fluid">
            <a class="navbar-brand" href="../index.html"><img src="../images/logo.png" alt="logo"></a>
            <button class="navbar-toggler" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvasNavbar"
                    aria-controls="offcanvasNavbar">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="offcanvas offcanvas-end" tabindex="-1" id="offcanvasNavbar"
                 aria-labelledby="offcanvasNavbarLabel">
                <div class="offcanvas-header">
                    <h5 class="offcanvas-title" id="offcanvasNavbarLabel">Offcanvas</h5>
                    <button type="button" class="btn-close text-reset" data-bs-dismiss="offcanvas"
                            aria-label="Close"></button>
                </div>
                <div class="offcanvas-body">
                    <ul class="navbar-nav justify-content-end fw-bold fs-6 text-uppercase flex-grow-1 pe-3 gap-3">
                        <li class="nav-item">
                            <a class="nav-link active" aria-current="page" href="../index.html">Home</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#"></a>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="nav-link dropdown-toggle" href="#" id="dropdownId" data-bs-toggle="dropdown"
                               aria-haspopup="true" aria-expanded="false">Pages</a>
                            <div class="dropdown-menu" aria-labelledby="dropdownId">
                                <a class="dropdown-item" href="../index.html">Blog</a>
                                <a class="dropdown-item" href="../index.html">Blog Single</a>
                            </div>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#">Blog</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#">Contact</a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </nav>
</header>

<main>
    <div id="appnox-latest-blog-area">
        <div class="container">
            <div class="row">
                <div class="blog-details-wraper">
                    <div class="blog-details-content">

                        <h2 style="font-weight: bold;text-align: center;color: black"> Stance Detection </h2>
                        <p style="font-size: 20px;color: darkgrey;text-align: center">创建日期：2024年06月02日</p>

                        <!--                            <img src="static/picture/details-1.jpg" alt="">-->
                        <ul>
                            <li><a href="#section1">1 - Task Definition </a></li>
                            <li><a href="#section2">2 - Dataset </a></li>
                            <li><a href="#section3">3 - Method </a></li>
                        </ul>

                        <h3 id="section1" style="color: coral;margin-top: 50px;font-weight: bold">1. Task Definition
                        </h3>
                        <h5>1.1 Cross-target Stance Detection</h5>
                        <h5>1.2 Multi-modal Stance Detection</h5>
                        <h5>1.3 Multi-topic Multi-target Stance Detection in Social Media (Our)</h5>
                        <p> &ensp;&ensp;&ensp; 首要说明：这个工作应该不算是new task，顶多是new dataset，其主要包括多个主题：体育、娱乐、政治等，以及多个不同的target（也就是多个事件）</p>
                        <p> &ensp;&ensp;&ensp; Motivation: </p>

                        <h5>1.4 Multi-modal Stance Detection in Social Media (Our)</h5>
                        <p>&ensp;&ensp;&ensp;最近受到Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs ([CVPR 2024 Workshop)的启发，
                            其主要动机：专注于引入外部知识来回答问题，开发专门用于处理外部知识的架构，而不是提出一个新颖的框架或者vision-and-language adapters。
                            关注数据集：MLLM处理与外部数据相关的Query能力的评估（需要引入外部知识的评估） Infoseek 和 Encyclopedic-VQA. </p>
                        <p>&ensp;&ensp;&ensp;号称：第一个利用外部资源检索能力的MLLM</p>
                        <div style="text-align: center"><img src="../images\stance\wiki-llava.jpg" alt="" style="zoom:50%"></div>
                        <p>&ensp;&ensp;&ensp;第一阶段（从文档中提取文档、图像、文本标题）： 输入图像I，使用文档标题作为可检索键，在外部知识中进行近似k-最近邻搜索。</p>
                        <p>&ensp;&ensp;&ensp;第二阶段（知识检索器返回与上述过程检索到的最相关项目相关联的前k个文档）： 分析每个检索到的文档，识别和用户问题最相关的段落，使用Contriever框架嵌入每个选定文档的块，
                            计算嵌入之间的内积作为相似性，每个文档检索n个最适当的段落，得到 K*n个段落 。最终Prompt设计，丰富了上下文：</p>
                        <p>&ensp;&ensp;&ensp;看完后内心第一反应，就这？作为audience，看到一张图片，第一步是思考object，与其有关的事件，再基于文本信息从有关事件筛选出真正有用的事件。</p>
                        <h3 id="section2" style="color: coral;margin-top: 50px;font-weight: bold">2. Dataset
                        </h3>
                        <h5>SemEval-2016</h5>
                        <p> SemEval-2016 is the first stance detection dataset collected from Twitter, which contains
                            4870 stance-bearing tweets towards different targets. Each tweet is classified as “favor”,
                            “against” or “none”. Following the previous work (Wei and Mao, 2019), we use the tweets from
                            four targets, including Donald Trump (DT), Hillary Clinton (HC), Legalization of Abortion
                            (LA), and Feminist Movement (FM). These targets are commonly utilized to
                            evaluate the cross-target stance classification.</p>
                        <h5>Wt-wt</h5>
                        <p>The largest available stance detection dataset so far, which consists of 51,284 tweets in
                            discussing mergers and acquisition operations between companies. Wt-wt contains 8 companies:
                            CVS Health (CVS), Aetna (AET), Cigna (CI), Express Scripts (ESRX), Anthem (ANTM), Humana
                            (HUM), Disney (DIS), and 21st Century Fox (FOXA), which are categorized into two domains
                            (industries), i.e. Healthcare (CVS, AET, CI, ESRX, ANTM, and HUM) and Entertainment (DIS and
                            FOXA). Each sentence refers to an operation of two companies and a stance label from support
                            (corresponding to favor when computing pragmatics weight), refute (corresponding to
                            against), comment or unrelated. </p>
                        <h5>PStance</h5>
                        <p> Stance detection determines whether the author of a text is in favor of, against or neutral
                            to a specific target and provides valuable insights into important events such as
                            presidential election. However, progress on stance detection has been hampered by the
                            absence of large annotated datasets. In this paper, we present P-Stance, a large stance
                            detection dataset in the political domain, which contains 21,574 labeled tweets. </p>
                        <p> 21,574 English tweets in the political domain and each tweet is annotated with a stance toward one of three different targets: “Donald Trump,” “Joe Biden,” and “Bernie Sanders.”</p>
                        <h3 id="section3" style="color: coral;margin-top: 50px;font-weight: bold">3. Methods</h3>
                        <h5>
                            <a href="https://wrap.warwick.ac.uk/149336/1/WRAP-Target-adaptive-graph-cross-target-stance-detection-2021.pdf">3.1
                                2021 www Target-adaptive Graph for Cross-target Stance Detection</a></h5>
                        <p>在实践中，我们需要处理注释的训练数据中看不到的目标。因此，检测未知或看不见的目标的姿态是一个重要的研究问题。
                            本文提出了一种新的方法，可以自动识别和调整单词在立场表达中相对于特定目标所扮演的目标相关和目标无关的角色，从而实现跨目标立场检测。</p>
                        <div style="text-align: center"><img src="../images\stance\3-1.jpg" alt="" style="zoom:50%"></div>
                        <p>为了更好地解决跨目标立场检测问题，本文作者提出了一种新颖的框架，通过构建从目标内和跨目标视角的目标自适应异构图（包括句法依存和语用信息），
                            利用立场表达对目标的基本词级语用依赖性来实现。通过利用不同目标之间的相互作用，所提出的框架可以更准确地捕捉立场信息，并在不同目标下更好地提炼知识，提高可解释性。
                            具体来说：1）作者首先计算词级的目标特定语用权重。为了捕捉单词在针对目标的立场表达中的固有角色，作者计算该单词在目标语境中的相对出现频率，并与其他目标进行比较。
                            然后，作者利用带标注训练数据中的立场信息，推导出该单词的立场相关语用权重。接下来，作者构建一个目标内图，其中节点是上下文单词，节点之间的边由语用信息和依存解析结果决定。
                            连接上下文单词的边的权重由目标特定语用权重决定。2）为了为每个单词生成目标特定的语用权重，作者考虑每个单词在不同已知目标中的分布情况，
                            以识别哪些单词是推导针对不同目标（包括未知目标）的立场表达的线索。在这里，作者仍然采用从带标注的训练数据中提取的立场信息来计算每个单词在所有目标中的语用权重，
                            然后依赖树和跨目标词级语用权重来派生另一语用依存图的每条边（称为跨目标图）。</p>
                        <h5>
                            <a href="https://www.researchgate.net/profile/Penghui-Wei/publication/334578182_Modeling_Transferable_Topics_for_Cross-Target_Stance_Detection/links/5d8e0493458515202b6dba39/Modeling-Transferable-Topics-for-Cross-Target-Stance-Detection.pdf">3.2
                                2019 SIGIR Modeling Transferable Topics for Cross-Target Stance Detection</a></h5>
                        <p>有针对性的立场检测旨在对固执己见的文本对预定义目标的态度进行分类。以前的方法主要集中在目标设置中，即使用特定于同一目标的数据来训练和测试模型。
                            在实际情况下，我们关注的目标可能很少或没有标记数据，这限制了我们训练特定目标的模型。
                            在本文中，我们研究了跨目标立场检测问题，利用源目标的标记数据来学习可以适应目标的模型。</p>
                        <div style="text-align: center"><img src="../images\stance\3-2.jpg" alt="" style="zoom:50%"></div>
                        <p>跨目标立场检测任务的关键研究挑战在于如何有效地建模可转移的知识，以促进在不同目标之间的适应。直观上，用户经常讨论某个目标的子主题，关于这些主题的表达可以用来推断他们对目标的立场。
                            此外，两个目标之间共享的常见主题可以作为可转移的知识，帮助模型在目标之间的适应。作者旨在将这种主题知识融入立场检测模型，以提高其跨目标适应能力。
                            为此，作者提出了一种跨目标立场检测方法，该方法将主题知识获取和目标不变文本表示学习整合到一个统一的端到端框架中。为了有效获取可转移的主题知识并使这一过程能够通过反向传播进行训练，
                            作者采用神经变分推理方法，利用源目标和目标目标的无标签数据生成潜在主题，并利用获取的主题知识增强文本表示。为了进一步促进模型学习更多目标不变的表示，作者采用对抗训练技术来优化模型。</p>
                        <h5><a href="https://arxiv.org/pdf/2310.14450">2023  EMNLP TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings</a></h5>
                        <p>在这项工作中，作者利用来自3074个新闻网站的新闻文章数据集、MPNet模型、Parrot转述和Flan-T5-XL，从不同网站提取并配对具有相似主题的段落，用于训练主题感知（TAW）编码模型。
                            作者提供了238228条扩展数据集（其中来自任何一个给定网站的段落不超过1000个）和984539条未过滤数据集（来自任何给定网站的不受限制的段落数量）。
                            动机：立场检测对于理解互联网上的不同态度和信仰非常重要。然而，考虑到一篇文章对给定主题的立场往往高度依赖于该主题，因此很难建立一个能够推广到未见主题的立场检测模型。
                            在这项工作中，作者建议使用对比学习以及覆盖各种不同主题的新闻文章的未标记数据集来训练主题不可知（TAG）和主题感知（TAW）嵌入，用于下游立场检测。</p>
                        <div style="text-align: center"><img src="../images\stance\3-3.jpg" alt="" style="zoom:50%"></div>
                        <p>几项研究已经建立了特定主题的立场分类器，并在特定目标上取得了令人满意的结果；然而，这些方法往往无法推广到其训练领域之外的主题，限制了它们在现实世界中的应用。
                            最近的研究试图通过利用通用立场特征、常识推理和广义的主题表示来缓解这个问题，在预测先前未见过的主题（零样本立场检测）和训练样本较少的主题（少样本立场检测）方面取得了更好的性能。
                            基于这些见解，作者创建并发布了用于设计主题感知（TAW）嵌入和广义主题无关（TAG）立场嵌入的合成数据集，以用于下游立场分类任务。通过利用主题感知和主题无关的视角和嵌入，
                            作者的完整TATA模型在零样本和少样本立场分类设置中均在VAST基准数据集上达到了最先进的性能。</p>
                        <p>具体而言，作者利用一个非结构化新闻文章数据集，并使用T5-Flan语言模型从特定段落中提取主题，训练了一个带有三元组损失的主题感知（TAW）嵌入层。通过使用三元组损失，作者强制具有相似主题的训练元素具有相似的嵌入，而具有不同主题的训练元素具有不同的嵌入。
                            通过在创建这些主题嵌入时使用一个包含多样且广泛的自动提取主题的未标记新闻文章数据集，而不是像其他研究那样简单地依赖昂贵且精心标注的立场数据集，这使得这些主题嵌入能够包含许多不同主题之间的关系。</p>
                        <p>类似地，对于主题无关（TAG）嵌入，在首先使用原始文本的转述版本扩展原始VAST训练数据集之后，作者利用对比学习目标提取广义立场特征。通过使用对比学习，作者强制具有相同立场的训练实例具有相似的嵌入，
                            同时强制具有不同立场的训练实例具有不同的嵌入。这使得TAG层能够建模出对于在给定示例中分类立场重要的通用立场特征。
                            将主题感知（TAW）和主题无关（TAG）视角结合到一个模型TATA中，作者在VAST数据集的零样本和少样本设置中实现了最先进的性能。
                            作者的TATA模型在SEM16t6数据集的零样本设置中也取得了竞争力的结果。
                            通过在合成数据集上进行训练，利用跨不同主题的共同立场特征（TAG），并利用丰富的嵌入潜在特征（TAW）提取特定主题的具体特征，
                            作者的TATA模型在当前的立场分类基准上实现了最先进的性能。</p>
                        <p>Question: Emmm 我对这篇工作有些无语，为什么是新闻文章的立场，而不是相应评论？</p>

                        <h5><a href="http://arxiv.org/abs/1908.03146">2019 ACM HCI: Your stance is exposed! analysing possible factors for stance detection on social media</a></h5>
                        <p>从多大程度上可以推断出用户对某个主题的立场呢？大多数关于立场检测的研究都集中在分析用户关于给定主题的帖子以预测立场。然而，社交媒体中的立场可以从可能反映用户立场（包括帖子和在线互动）的信号混合中推断出来。
                            本文研究了用户的各种在线特征，以检测他们对不同主题的立场。我们比较了多组特征，包括主题内容，网络交互，用户偏好和在线网络连接。
                            本文目标是了解可以反映用户立场的在线信号。实验应用于来自SemEval立场检测任务的推文数据集，该任务涵盖五个主题。研究结果表明，可以通过用户在线活动的多个信号来检测用户的立场，
                            包括他们关于主题的帖子，他们与之交互或跟踪的网络，他们访问的网站以及他们喜欢的内容。
                            使用不同网络特征的立场建模的性能与仅使用文本内容的最新报告模型相当。此外，结合网络和内容功能，在SemEval数据集上获得了迄今为止报告的最高性能，F-measure为72.49％。
                            作者进一步展示了一个广泛的分析，以显示这些不同的特征如何能够揭示立场。本研究结果具有明显的隐私含义，他们强调用户的在线社会网络中的立场是根深蒂固的。
                            原则上，可以通过他们的交互和联系进行分析，即使他们没有发布有关该主题的内容。</p>
                        <h5><a href="http://arxiv.org/abs/1908.03181">2019 ICSI: Assessing Sentiment of the Expressed Stance on  Social Media</a></h5>
                        <p>立场检测是对给定的主题或实体进行支持或反对的观点推断的任务。人们可以通过使用正面或负面语言来表达对主题的观点。本文从情感极性的角度考察了社会媒体如何表达这种立场。
                            在观点发现方面，人们对立场和情绪之间的相似性存在明显的误解，其中负面情绪被认为是反对立场，积极的情绪被认为是支持立场。
                            为了分析立场和情感之间的关系，本文构建了一个包含四个主题的新数据集，并研究人们如何表达他们对这些主题的观点。
                            作者通过对流行的立场基准SemEval立场数据集进行进一步分析来验证结果。研究表明，情绪和立场不是高度一致的，因此简单的情感极性不能仅用于表示对特定主题的立场。</p>

                    </div>
                </div>
            </div>
        </div>
    </div>
</main>
<script src="../js/jquery-1.11.0.min.js"></script>
<script src="https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/5.3.0-alpha3/js/bootstrap.bundle.min.js"
        integrity="sha384-ENjdO4Dr2bkBIFxQpeoTz1HIcje39Wm4jDKdf19U8gI4ddQ3GYNS7NTKfAdVQSZe"
        crossorigin="anonymous"></script>
</body>
</html>